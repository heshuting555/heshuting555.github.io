
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="robots" content="index,follow">
    <meta name="keywords" content="Shuting He; Zhejiang University; Segmentation">
    <link rel="author" href="https:heshuting555.github.io/">
    <title>Shuting He's Homepage</title>
    <link rel="stylesheet" href="style.css" type="text/css" />
    <link rel="apple-touch-icon" sizes="180x180" href="favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicon/favicon-16x16.png">
    <link rel="manifest" href="favicon/site.webmanifest">
    <link rel="mask-icon" href="favicon/safari-pinned-tab.svg" color="#5bbad5">
    <meta name="msapplication-TileColor" content="#9f00a7">
    <meta name="theme-color" content="#ffffff">
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico">
    <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

</head>


<body>
    <div id="container">
        <div id="header">
            <h1><a>Shuting He</a></h1>
            <h2>Dr.</h2>
            <div class="clear"></div>
        </div>


        
        <div id="body">
            <div id="Biography">
                <h2>Short Biography<font size=4></font></h2>
<!--                 <HR style="FILTER: alpha(opacity=60,finishopacity=0,style=3)" width="98%" color=#F0F0F0 SIZE=1> -->
                <HR color=#F0F0F0 width="97%" SIZE=1><br>
                <table class="table-bio">
                    <!-- <td class="col-bio">   --> 
                    <p style="text-align:justify; text-justify:inter-ideograph;padding-right:36px;"> 
                     Shuting He is currently a tenure-track Assistant Professor at Shanghai University of Finance and Economics (<a href="https://english.sufe.edu.cn/" target="_blank">SUFE</a>). Prior to that, she was a Research Fellow at Nanyang Technological University (<a href="https://www.ntu.edu.sg/Pages/home.aspx" target="_blank">NTU</a>) in Singapore. She received the Ph.D. degree from Zhejiang University (<a href="https://www.zju.edu.cn/english/" target="_blank">ZJU</a>), Hangzhou China, in 2023, and the B.E. degree from Xiamen University (<a href="http://en.xmu.edu.cn/" target="_blank">XMU</a>), Xiamen China, in 2018. Her research interests include machine learning and computer vision, with special emphasis on low-shot learning, person re-identification, and segmentation. She serves/served as an Area Chair for CVPR 2026 and BMVC 2025. <br><br>

                     <a href="https://scholar.google.com/citations?user=mO40IjIAAAAJ&hl=en" target="_blank"><img src="assets/google_scholar.png" height="20px"></a>
                    <a href="https://github.com/heshuting555" target="_blank"><img src="assets/github.png" height="20px"></a> 
                    <object id="object" data="assets/envelope.svg" width="20" height="20" type="image/svg+xml" style="position:relative;top:4px;"></object>heshuting555@gmail.com
                     <br>
                    </p>

                    <br><b> <font color="DeepPink">长期招收博士、硕士研究生及本科实习生。感兴趣的同学联系：shuting.he[AT]sufe.edu.cn</font><br></b>

                </table>
            </div>


<div id="News">
                <h2>News</h2>
                <HR color=#F0F0F0 width="97%" SIZE=1>
                <div class="news" style="overflow:auto; height:200px; Width:99%;padding-top: 6px;">
                <ul>
                <li>[09, 2025]&nbsp;&nbsp;&nbsp; Selected into <a href="https://elsevier.digitalcommonsdata.com/datasets/btchxktzyw/8" target="_blank" style="color:DeepPink; font-weight:bold;">Stanford University's list of the World's Top 2% Scientists.</a></h7></li>
                <li>[09, 2025]&nbsp;&nbsp;&nbsp; 2 papers accepted to <h7>NeurIPS 2025</h7></li>
                <li>[09, 2025]&nbsp;&nbsp;&nbsp; Serving as an <h7>Area Chair for CVPR 2026</h7></li>
                <li>[08, 2025]&nbsp;&nbsp;&nbsp; 1 paper accepted to <h7>TPAMI</h7></li>
                <li>[07, 2025]&nbsp;&nbsp;&nbsp; 3 papers accepted to <h7>ACMMM 2025</h7></li>
                <li>[07, 2025]&nbsp;&nbsp;&nbsp; Serving as an <h7>Area Chair for BMVC 2025</h7></li>
                <li>[06, 2025]&nbsp;&nbsp;&nbsp; 2 papers accepted to <h7>ICCV 2025</h7>, with one paper selected as <b><font color="DeepPink">Highlight</font></b></li>
                <li>[05, 2025]&nbsp;&nbsp;&nbsp; 1 paper accepted to <h7>ICML 2025</h7> as <b><font color="DeepPink">Oral</font></b></li>
                <li>[04, 2025]&nbsp;&nbsp;&nbsp; 1 papers accepted to <h7>TIFS</h7></li>
                <li>[03, 2025]&nbsp;&nbsp;&nbsp; 1 papers accepted to <h7>SIGIR 2025</h7></li>
                <li>[02, 2025]&nbsp;&nbsp;&nbsp; 1 papers accepted to <h7>CVPR 2025</h7></li>
                <li>[01, 2025]&nbsp;&nbsp;&nbsp; 3 papers accepted to <h7>AAAI 2025</h7></li>
                </ul>
             </div><br>        
            </div>



            <div id="Publications">
                <h2>Selected Publications<font size=4> [<a href="https://scholar.google.com/citations?user=mO40IjIAAAAJ&hl=en" target="_blank">Google Scholar</a>]</font></h2>
                <HR color=#F0F0F0 width="97%" SIZE=1><br>
                <table class="table-pub"> 
                    <tr>
                        <td class="col-pubimage"><a href="https://arxiv.org/abs/x" target="_blank"><img src="images/MeViS++.png"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>MeViS: A Multi-Modal Dataset for Referring Motion Expression Video Segmentation</h6><br>
                                Henghui Ding, Chang Liu, <b>Shuting He</b><sup>✉️</sup>, Kaining Ying, Xudong Jiang, Chen Change Loy, Yu-Gang Jiang<sup>✉️</sup><br>
                                <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2025.</i><br>
                                <span>✉️ Corresponding Author</span><br>
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td class="col-pubimage"><a href="https://openreview.net/pdf/bee67a61e457627319addc3d30653b1da1894324.pdf" target="_blank"><img src="images/ReferSplat.png"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>ReferSplat: Referring Segmentation in 3D Gaussian Splatting</h6><br>
                                <b>Shuting He</b>, Guangquan Jie, Changshuo Wang, Yun Zhou, Shuming Hu, Guanbin Li, Henghui Ding<br>
                                <i>International Conference on Machine Learning (ICML), 2025.</i><br>
                                <i><b><d>Oral, Acceptance Rate 1.0%.</i></b></d><br>
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td class="col-pubimage"><a href="https://www.arxiv.org/abs/2507.12857" target="_blank"><img src="images/score.png"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>SCORE: Scene Context Matters in Open-Vocabulary Remote Sensing Instance Segmentation</h6><br>
                                Shiqi Huang, <b>Shuting He</b>, Huaiyuan Qin and Bihan Wen<br>
                                <i>IEEE International Conference on Computer Vision (ICCV), 2025.</i><br>
                                <i><b><d>Highlight, Acceptance Rate 5.0%.</i></b></d><br>
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td class="col-pubimage"><a href="https://www.arxiv.org/abs/x" target="_blank"><img src="images/PSP.png"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>Prompt-Softbox-Prompt: A Free-Text Embedding Control for Image Editing</h6><br>
                                Yitong Yang, Yinglin Wang<sup>✉️</sup>, Tian Zhang, Jing Wang, <b>Shuting He</b><sup>✉️</sup><br>
                                <i>ACM International Conference on Multimedia (ACM MM), 2025.</i><br>
                                <span>✉️ Corresponding Author</span><br>

                            </div>
                        </td>
                    </tr>                    
                    <tr>
                        <td class="col-pubimage"><a href="https://arxiv.org/abs/2404.03645" target="_blank"><img src="images/DsHmp.png"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>Decoupling Static and Hierarchical Motion Perception for Referring Video Segmentation</h6><br>
                                <b>Shuting He</b>, Henghui Ding<br>
                                <i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2024.</i><br>
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td class="col-pubimage"><a href="https://arxiv.org/abs/2407.13761" target="_blank"><img src="images/segpoint.png"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>SegPoint: Segment Any Point Cloud via Large Language Model</h6><br>
                                <b>Shuting He</b>, Henghui Ding, Xudong Jiang, Bihan Wen<br>
                                <i>European Conference on Computer Vision (ECCV), 2024.</i><br>
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td class="col-pubimage"><a href="https://arxiv.org/abs/2407.18244" target="_blank"><img src="images/refmask3d.png"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>RefMask3D: Language-Guided Transformer for 3D Referring Segmentation</h6><br>
                                <b>Shuting He</b>, Henghui Ding<br>
                                <i>ACM International Conference on Multimedia (ACM MM), 2024.</i><br>
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td class="col-pubimage"><a href="https://arxiv.org/abs/2403.19975" target="_blank"><img src="images/context.png"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>Context-Aware Integration of Language and Visual References for Natural Language Tracking</h6><br>
                                Yanyan Shao, <b>Shuting He</b>, Qi Ye, Yuchao Feng, Wenhan Luo, Jiming Chen<br>
                                <i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2024.</i><br>
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td class="col-pubimage"><a href="https://openreview.net/pdf?id=a7mdX3ZIoj" target="_blank"><img src="images/Dual.png"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>Dual-head Genre-instance Transformer Network for Arbitrary Style Transfer</h6><br>
                                Meichen Liu, <b>Shuting He</b>, Songnan Lin, Bihan Wen<br>
                                <i>ACM International Conference on Multimedia (ACM MM), 2024.</i><br>
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td class="col-pubimage"><a href="https://henghuiding.github.io/MeViS" target="_blank"><img src="images/ICCV23_MeViS.webp"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>MeViS: A Large-scale Benchmark for Video Segmentation with Motion Expressions</h6><br>
                                Henghui Ding, Chang Liu, <b>Shuting He</b>, Xudong Jiang, Chen Change Loy<br>
                                <i>IEEE International Conference on Computer Vision (ICCV), 2023.</i><br>
                                <i><a href="" target="_blank"><d><b>MeViS</b></d></a> A benchmark dataset of Video Segmentation with Motion Expressions. <a href="https://henghuiding.github.io/MeViS" target="_blank">&#128293;Project Page&#128293;</a> </i><br>
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="col-pubimage"><a href="https://henghuiding.github.io/MOSE" target="_blank"><img src="images/0442a954.webp"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>MOSE: A New Dataset for Video Object Segmentation in Complex Scenes</h6><br>
                                Henghui Ding, Chang Liu, <b>Shuting He</b>, Xudong Jiang, Philip H.S. Torr, Song Bai<br>
                                <i>IEEE International Conference on Computer Vision (ICCV), 2023.</i><br>
                                <i><a href="https://henghuiding.github.io/MOSE" target="_blank"><d><b>MOSE</b></d></a> A benchmark dataset of co<b><d>M</b></d>plex video <b><d>O</d></b>bject <b><d>SE</d></b>gmentation <a href="https://henghuiding.github.io/MOSE" target="_blank">&#128293;Project Page&#128293;</a></i><br>
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="col-pubimage"><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/He_Primitive_Generation_and_Semantic-Related_Alignment_for_Universal_Zero-Shot_Segmentation_CVPR_2023_paper.pdf" target="_blank"><img src="images/PADing.png"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>Primitive Generation and Semantic-related Alignment for Universal Zero-Shot Segmentation</h6><br>
                                <b>Shuting He</b>, Henghui Ding, Wei Jiang<br>
                                <i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2023.</i><br>
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="col-pubimage"><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/He_Semantic-Promoted_Debiasing_and_Background_Disambiguation_for_Zero-Shot_Instance_Segmentation_CVPR_2023_paper.pdf" target="_blank"><img src="images/D2Zero.png"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>Semantic-Promoted Debiasing and Background Disambiguation for Zero-Shot Instance Segmentation</h6><br>
                                <b>Shuting He</b>, Henghui Ding, Wei Jiang<br>
                                <i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2023.</i><br>
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="col-pubimage"><a href="https://arxiv.org/abs/2305.14335.pdf" target="_blank"><img src="images/PAPFZS3D.png"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>Prototype Adaption and Projection for Few- and Zero-shot 3D Point Cloud Semantic Segmentation</h6><br>
                                <b>Shuting He</b>, Xudong Jiang, Wei Jiang and Henghui Ding<br>
                                <i>IEEE Transactions on Image Processing (TIP), 2023.</i><br>
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="col-pubimage"><a href="https://arxiv.org/abs/2311.07514.pdf" target="_blank"><img src="images/VGSG.png"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>VGSG: Vision-Guided Semantic-Group Network for Text-based Person Search</h6><br>
                                <b>Shuting He</b>, Hao Luo, Wei Jiang, Xudong Jiang, and Henghui Ding<br>
                                <i>IEEE Transactions on Image Processing (TIP), 2023.</i><br>
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="col-pubimage"><a href="https://arxiv.org/abs/2309.03558.pdf" target="_blank"><img src="images/GRANet.png"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>Region Generation and Assessment Network for Occluded Person Re-Identification</h6><br>
                                <b>Shuting He</b>, Weihua Chen, Kai Wang, Hao Luo, Fan Wang, Wei Jiang and Henghui Ding<br>
                                <i>IEEE Transactions on Information Forensics and Security (TIFS), 2023.</i><br>
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td class="col-pubimage"><a href="https://openaccess.thecvf.com/content/ICCV2021/papers/He_TransReID_Transformer-Based_Object_Re-Identification_ICCV_2021_paper.pdf" target="_blank"><img src="images/TransReID.png"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>TransReID: Transformer-based Object Re-Identification</h6><br>
                                <b>Shuting He</b>, Hao Luo, Pichao Wang, Fan Wang, Hao Li, Wei Jiang<br>
                                <i>IEEE International Conference on Computer Vision (ICCV), 2021.</i><br>
                            </div>
                        </td>
                    </tr>

                    
                </table>
            </div>
            
            <div id="Activities">
                <h2>Selected Awards and Honors</h2>
                <HR color=#F0F0F0 width="97%" SIZE=1><br>
                <ul>
                    <li>CVPR 2023 Doctoral Consortium, 13% Acceptance Rate</li>
                    <li>1st Place, IEEE CVPR 2021 AI CITY Challenge</li>
                    <li>1st Place, IEEE IJCAI iQIYI 2020 iCartoonFace Challenge</li>
                    <li>1st Place, IEEE ECCV 2020 Visual Domain Adaptation Challenge</li>

                </ul>
            </div>
            <div id="Activities">
                <h2>Activities</h2>
                <HR color=#F0F0F0 width="97%" SIZE=1><br>
                <ul>
                    <li>Area Chair: CVPR, BMVC.</li>
                    <!-- <li>Conference Reviewer: CVPR, ICCV, ECCV, ICLR, ICML, NeurIPS, IJCAI, AAAI, ACM MM, etc.</li> -->
                    <li>Journal Reviewer: TPAMI, IJCV, TIP, TNNLS, TMM, TCSVT, CVIU, etc.</li>

                </ul>
            </div>
            <HR color=#F0F0F0 width="97%" SIZE=1>
            <center><font size=2>© Shuting He | Last updated: 03/09/2025</font></center>
        </div>
        <div class="clear"></div>
    </div>


<a href="https://clustrmaps.com/site/1btxe" title="Visit tracker" target="_blank"><img src="//www.clustrmaps.com/map_v2.png?d=Q15K1jgkjDhXHWt0Xs1B_x4drGMUMM_eRXp7kbtrV20&cl=ffffff"height="2"/ style="display:block;margin-top:5px;margin-bottom:0px;margin-left:auto;text-align:right"></a>
</body>

</html>
